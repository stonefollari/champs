{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAMPS Dataset Scalar Coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Michael Follari\n",
    "- [Predicting Molecular Properties](https://www.kaggle.com/c/champs-scalar-coupling)\n",
    "- UNCG Physics 2020\n",
    "- Dr. Ajay Covell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More plot styling can be found [here.](https://matplotlib.org/tutorials/introductory/customizing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "* structures.csv - `structures_df` - Contains the xyz coordinates of each atom within each molecule\n",
    "* train.csv - `train_df` - Contains the type and scalar_coupling_constant between every atoms pair within each molecule.\n",
    "\n",
    "### The following code imports both the above datasets, merges, and adds additional columns.\n",
    "* `displacement` column is added. The displacement between the two atoms in the bond.\n",
    "* The final dataset will contain every bond, the bond atoms, and locations of each atom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to dataset CSV / zip files\n",
    "structure_path = 'D:\\data\\champs\\zip\\structures.zip'\n",
    "train_path = 'D:\\data\\champs\\zip\\\\train.zip'\n",
    "test_path = 'D:\\data\\champs\\zip\\\\test.zip'\n",
    "train_bond_path = 'D:\\data\\champs\\zip\\\\train_bond.gz'\n",
    "test_bond_path = 'D:\\data\\champs\\zip\\\\test_bond.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Structure and Train CSV files, merge, calculate values, and save to Molecules CSV\n",
    "def merge_struct_dataset(path_struct, path_train, path_merged):\n",
    "    \n",
    "    # load in struct and train datasets\n",
    "    structures_df = pd.read_csv(path_struct)\n",
    "    train_df = pd.read_csv(path_train)\n",
    "\n",
    "    # Merge structure data onto train_df for each atom (atom_index_0 and atom_index_1). Hold in mol_df\n",
    "    mol_df = train_df.merge(structures_df, left_on=['molecule_name','atom_index_0'], right_on=['molecule_name','atom_index'])\n",
    "    mol_df = mol_df.merge(structures_df, left_on=['molecule_name','atom_index_1'], right_on=['molecule_name','atom_index'])\n",
    "\n",
    "    # drop extra columns from merge and rename\n",
    "    mol_df.drop(['atom_index_x','atom_index_y'], axis=1, inplace=True)\n",
    "    mol_df.rename(columns={'atom_x':'atom_0','atom_y':'atom_1','x_x':'x_0','y_x':'y_0','z_x':'z_0','x_y':'x_1','y_y':'y_1','z_y':'z_1'}, inplace=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    mol_df.to_csv(path_merged, compression=\"gzip\")\n",
    "    \n",
    "# adds new columns with calculated values to molecule df\n",
    "def add_all_calculations(df):\n",
    "    mol_df = add_mol_displacement(df)\n",
    "    mol_df = add_mol_angle(df)\n",
    "    return mol_df\n",
    "    \n",
    "# calculates the displacement for each atom interaction \n",
    "def add_mol_displacement(df):\n",
    "    df['displacement'] = df.apply(lambda row: calc_disp(row), axis=1)\n",
    "    return df\n",
    "\n",
    "# calculates the angle between the two atoms\n",
    "def add_mol_angle(df):\n",
    "    df['angle'] = df.apply(lambda row: calc_ang(row), axis=1)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "# calculates the angle between the two atoms\n",
    "def add_mol_eff(df):\n",
    "    df['eff'] = df.apply(lambda row: calc_eff(df, row), axis=1)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "# calculcates displacement on a passed row\n",
    "def calc_disp(row):\n",
    "    return np.linalg.norm(np.array([row['x_1']-row['x_0'],row['y_1']-row['y_0'],row['z_1']-row['z_0']]))\n",
    "\n",
    "# calc angle between\n",
    "def calc_ang(row):\n",
    "    u = np.array([row['x_0'],row['y_0'],row['z_0']])\n",
    "    v = np.array([row['x_1'],row['y_1'],row['z_1']])\n",
    "    return np.dot(u,v)/(np.linalg.norm(u)*np.linalg.norm(v))\n",
    "\n",
    "# calc some very poor and bad estimation value of potential\n",
    "def calc_eff(df, row):\n",
    "    \n",
    "    mol_name = row['molecule_name']\n",
    "    atom_0 = row['atom_index_0']\n",
    "    atom_1 = row['atom_index_1']\n",
    "    \n",
    "    # Get molecule structure\n",
    "    molecule_df = df[df.molecule_name == mol_name]\n",
    "    molecule_df_0 = molecule_df[(molecule_df.atom_index_0 == atom_0) | (molecule_df.atom_index_1 == atom_0) ]\n",
    "    eff_0 = molecule_df_0.apply( lambda row : row['displacement'] * row['angle'], axis=1 ).sum()\n",
    "    \n",
    "    molecule_df_1 = molecule_df[(molecule_df.atom_index_0 == atom_1) | (molecule_df.atom_index_1 == atom_1) ]\n",
    "    eff_1 = molecule_df_1.apply( lambda row : row['displacement'] * row['angle'], axis=1 ).sum()\n",
    "    \n",
    "    return eff_0 + eff_1\n",
    "\n",
    "\n",
    "\n",
    "# Saves df to path.\n",
    "def save_df(df, path):\n",
    "    df.to_csv(path, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge strucutre data with train and test data sets.\n",
    "* Only need to do once to generaete and save to dataframes as CSV files, then load as normal CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_struct_dataset(structure_path, train_path, train_bond_path)\n",
    "# merge_struct_dataset(structure_path, test_path, test_bond_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bond DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df = pd.read_csv( train_bond_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df = bond_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test_bond_df contains the same set of data for a differet set of bonds. This can be used to test. I did not see this as particularly useful, since test/train splitting can be done. This is maybe useful for hte actual competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_bond_df = pd.read_csv( test_bond_path )\n",
    "# test_bond_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv( test_path )\n",
    "struct_df = pd.read_csv( structure_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new calculated columns\n",
    "* This is only ran once, if df is saved (as it should be to avoid re-calculating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append new columns with calculated values\n",
    "# bond_df = add_all_calculations(mol_df)\n",
    "\n",
    "# Just adding one row, only need to do once\n",
    "# bond_df = add_mol_angle(bond_df)\n",
    "\n",
    "# bond_df = add_mol_eff(bond_df)\n",
    "\n",
    "# Save new df\n",
    "# bond_df.to_csv(train_bond_path, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n",
    "* Plotting of data, observe Scalar Coupling & Atom Displacement relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score Calculation functions\n",
    "* More information found at [here](https://www.kaggle.com/c/champs-scalar-coupling/overview/evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_type( y_test, y_calc ):\n",
    "    y = list(zip(y_test, y_calc))\n",
    "    error = sum( [abs(i - j) for i, j in y] )\n",
    "    return np.log10( error / len(y) )\n",
    "\n",
    "def score(types_data):\n",
    "    \n",
    "    total_score = 0\n",
    "    for typ in types_data:\n",
    "        total_score += score_type(typ)\n",
    "    return total_score / len(types_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting data points and models functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots Model with data points.\n",
    "# Scatter plot of test data points\n",
    "# Plots prediction function\n",
    "def plot_model( x_test, y_test, y_regs, title, x_bound=[None,None], y_bound=[None,None]):\n",
    "    \n",
    "    xmin = x_test.min() if x_bound[0] is None else x_bound[0]\n",
    "    xmax = x_test.max() if x_bound[1] is None else x_bound[1]\n",
    "    ymin = y_test.min() if y_bound[0] is None else y_bound[0]\n",
    "    ymax = y_test.max() if y_bound[1] is None else y_bound[1]\n",
    "    \n",
    "    plt.scatter(x_test,y_test, c='b')\n",
    "    \n",
    "    for y_reg in y_regs:\n",
    "        plt.plot(x_test, y_reg, linewidth=3, linestyle='solid')\n",
    "    \n",
    "#     plt.xlim([xmin * 0.99,xmax * 1.01])\n",
    "#     plt.ylim([ymin * 0.99,ymax* 1.01])\n",
    "    plt.title(title, size=22)\n",
    "    plt.xlabel('Displacement', size=22)\n",
    "    plt.ylabel('Scalar Coupling Constant', size=22)\n",
    "    plt.show()\n",
    "    \n",
    "# Shorthand to label plot\n",
    "def label_plot(title,xlabel,ylabel):\n",
    "    plt.title(title, size=22)\n",
    "    plt.xlabel(xlabel, size=22)\n",
    "    plt.ylabel(ylabel, size=22)\n",
    "\n",
    "\n",
    "# Plots data points for all bond types\n",
    "def datasetScatterPlot():\n",
    "    for bond in bond_types:\n",
    "        bond_type = bond_types[0]\n",
    "        X, y = get_disp_ang_coupling(bond_df, bond )\n",
    "        plt.scatter(X[0],y)\n",
    "        label_plot('Coupling Constant vs. Displacement','Displacement', 'Scalar Coupling Constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The different kinds of bonds present in the data\n",
    "* Eight different bond types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_types = bond_df.type.unique()\n",
    "print(bond_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching `(displacement, feature)` data for regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_displacement_coupling(df, bond_type):\n",
    "    df = df[ df.type == bond_type].sort_values(by=['displacement'])\n",
    "    # Split and return into x and y arrays\n",
    "    x = df['displacement'].values\n",
    "    y = df['scalar_coupling_constant'].values\n",
    "    return np.array([x,y])\n",
    "\n",
    "def get_disp_ang_coupling(df, bond_type):\n",
    "    df = df[ df.type == bond_type].sort_values(by=['displacement'])\n",
    "    # Split and return into x and y arrays\n",
    "    X = (df['displacement'].values,df['angle'].values)#np.array([list(a) for a in list(zip(df['displacement'],df['angle']))])\n",
    "    y = df['scalar_coupling_constant'].values\n",
    "    return [X,y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot of all Bond Data\n",
    "* Observing relationship between bond strength and displacement. There is clearly some relationship!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong clustering of bonds, relationship between displacement and coupling constant\n",
    "This is seen since the different bond types inhabit different spaces. Certain bonds have their own range of displacement strengths and scalar magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetScatterPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since there is a relationship between these features, we will now try to use simple Machine Learning models to try and predict the coupling constant as a function of both Bond Type and Displacement.\n",
    "The data will be split into their respective bond types. This is because this information is always known, we are trying to predict the coupling constant of a given bond. The information we are to work with is displacement between the two atoms that make up the bond. This information is given. The goal is to predict the coupling constant.\n",
    "\n",
    "Since there seems to be an appreciable relationship between disoplacement and coupling constant, we can proceed with these features.\n",
    "\n",
    "later in the notebook, an attempt to use the cosine of the angle between the bonds is explored. There is no strong relationship in that feature. Deriving more features from the data given, essentially just locations, is a challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- [scikit Learn Linear Regression](https://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(x_train, y_train, x_test):\n",
    "    # Train linear regression model\n",
    "    linear_reg = train_linear_regression(x_train, y_train)\n",
    "    \n",
    "    # Use linear regression to generate y value\n",
    "    return np.array(line_data_points(x_test,linear_reg.coef_, linear_reg.intercept_)).T[0]\n",
    "    \n",
    "def train_linear_regression(x,y):\n",
    "    # Linear Regression fit\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit( x.reshape(-1,1), y )\n",
    "    return reg\n",
    "\n",
    "def line_data_points(x_array, coef, intercept):\n",
    "    return [line_func(x, coef, intercept) for x in x_array]\n",
    "\n",
    "def line_func(x, coef, intercept):\n",
    "    return x*coef + intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression\n",
    "* [scikit Learn Random Forest Regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(x_train, y_train, x_test):\n",
    "    # Train Random Forest regression model\n",
    "    random_forest_reg = train_rand_forest(x_train, y_train)\n",
    "    \n",
    "    # Use Random Forest regression to generate y values\n",
    "    return random_forest_reg.predict(x_test.reshape(-1,1))\n",
    "\n",
    "def train_rand_forest(x, y):\n",
    "    # Train Random Forest\n",
    "    reg = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    reg.fit(x.reshape(-1,1), y)\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trains models for data\n",
    "#### `evaluate_models` function does the following for all 8 bond types.\n",
    "* Splits data into test, train\n",
    "* Fits with model\n",
    "* Generate predicted values for test data\n",
    "* Scores against known test values\n",
    "* Returns score\n",
    "* Optionally also generates a plot with scatter plot of test data and model on single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(plot=False):\n",
    "\n",
    "    title = \"Regression of Scalar-Coupling-Constant vs. Bond Displacement : \"\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(10)\n",
    "    \n",
    "    sum_score = 0;\n",
    "    for bond_type in bond_types:\n",
    "\n",
    "        # Get x y test/train. Displacement and Bond strength\n",
    "        x, y = get_displacement_coupling(bond_df, bond_type )\n",
    "                \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=433)\n",
    "        x_test.sort() # Sort training values (mostly for plotting)\n",
    "\n",
    "        # Train and predict Linear regression\n",
    "        y_linear_regression = linear_regression(x_train, y_train, x_test)\n",
    "\n",
    "        # Train and predict Random Forest\n",
    "        y_random_forest_regression = random_forest(x_train, y_train, x_test)\n",
    "\n",
    "        # Calculate score for regression on type\n",
    "        linear_score = score_type( y_test, y_linear_regression) \n",
    "        forest_score = score_type( y_test, y_random_forest_regression) \n",
    "\n",
    "        # Print result\n",
    "        print(bond_type + ' has score :     Linear: ', round(linear_score, 5), '     Forest: ', round(forest_score,5 ))\n",
    "        \n",
    "        # Plot only if desired\n",
    "        if plot:\n",
    "            y_regs = [y_linear_regression, y_random_forest_regression]\n",
    "            plot_model(x_test, y_test, y_regs, title+bond_type,[x_train.min(),x_train.max()], [y_train.min(),y_train.max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of models\n",
    "* Score without plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_models(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs of the models\n",
    "* Score with plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluate_models(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine of Angle Exploration\n",
    "### Perhaps the angle has some relationship as well, this is explored below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDatasetScatterPlot():\n",
    "    for bond in bond_types:\n",
    "        bond_type = bond_types[0]\n",
    "        X, y = get_disp_ang_coupling(bond_df, bond )\n",
    "        plt.scatter(X[1],y)\n",
    "        label_plot('Coupling Constant vs. Cosine of Angle','Cos(theta)', 'Scalar Coupling Constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No relationship between cosine of angle and coupling constant\n",
    "This is seen as every bond type is spread across the entire angle cos() range, -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosineDatasetScatterPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No relationship between displacement and cosine of angle between atoms.\n",
    "This is seen since for a given displacement, the  range of cosine values is from -1 to 1, full range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosDispDatasetScatterPlot():\n",
    "    for bond in bond_types:\n",
    "        bond_type = bond_types[0]\n",
    "        X, y = get_disp_ang_coupling(bond_df, bond )\n",
    "        plt.scatter(X[0],X[1])\n",
    "        label_plot('Displacement vs. Cosine of Angle','Displacement', 'Cos(theta)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosDispDatasetScatterPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "## This is just more exploration being done.\n",
    "Since we only have one usedul dimension, displacement, as of now, clustering is not possible. This is here incase in the future another dimension proves useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets.samples_generator import make_blobs\n",
    "# XX, yy = make_blobs(n_samples=300, centers=4,\n",
    "#                   random_state=0, cluster_std=0.60)\n",
    "# plt.scatter(XX[:, 0], XX[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = KMeans(4)  # 4 clusters\n",
    "# est.fit(XX)\n",
    "# y_kmeans = est.predict(XX)\n",
    "# plt.scatter(XX[:, 0], XX[:, 1], c=y_kmeans, s=50, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import cluster\n",
    "\n",
    "bond_type = bond_types[0]\n",
    "x, y = get_displacement_coupling(bond_df, bond_type )\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=433)\n",
    "x_test.sort() # Sort training values (mostly for plotting)\n",
    "\n",
    "X_train = np.array([list(a) for a in list(zip(x_train,y_train))])\n",
    "X_test = np.array([list(a) for a in list(zip(x_test,y_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = KMeans(num_clusters)\n",
    "est.fit(X_train)\n",
    "y_kmeans = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral = cluster.SpectralClustering(\n",
    "#         n_clusters=num_clusters, eigen_solver='arpack',\n",
    "#         affinity=\"nearest_neighbors\")\n",
    "    \n",
    "# spectral.fit(X_train)\n",
    "# y_spectral = spectral.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clusrtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward = cluster.AgglomerativeClustering(\n",
    "#         n_clusters=num_clusters, linkage='ward')\n",
    "# ward.fit(X_train)\n",
    "# y_ward = ward.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This result does not mean anything. We only have one feature.\n",
    "It's just useless, look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_test[:, 0], X_test[:, 1], c=y_kmeans, s=50, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "* To improve the Random Forest Regression result we got, XGBoost can be used. This should result in a better fit.\n",
    "* I was unable to get this library working, unsure. Not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining and formatting data for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_type = bond_types[0]\n",
    "x, y = get_displacement_coupling(bond_df, bond_type )\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=433)\n",
    "x_test.sort() # Sort training values (mostly for plotting)\n",
    "\n",
    "X_train = np.array([list(a) for a in list(zip(x_train,y_train))])\n",
    "X_test = np.array([list(a) for a in list(zip(x_test,y_test))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "# read in data\n",
    "dtrain = xgb.DMatrix(X_train, label=[1]*531849 )\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "# specify parameters via map\n",
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "num_round = 10\n",
    "bst = xgb.train(param, dtrain)\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_displacement_coupling(bond_df,bond_type)[0][:177284]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_test, y_test)\n",
    "plt.scatter(x_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network\n",
    "I am utilizing TensorFlow, as it is specialized and allows GPU support -- which should greatly speed up whataever I do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# import tensorflow_docs as tfdocs\n",
    "# import tensorflow_docs.plots\n",
    "# import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a simple FFNN\n",
    "The First NN input layer is fed the follwing information:\n",
    "* Type (over 8 neurons)\n",
    "* atom 1 and 2 x,y,z (6 neurons)\n",
    "* displacement (1 neuron)\n",
    "\n",
    "From this, I would like the NN to classify which Sub-species it has, using Type and XYZ / Displacement. There are at most 8 (rough estimate) sub species for any given bond type.\n",
    "Since it does not seem very complicated, I would imagine a small number of layers / neurons could be used. I started with 2 dense layers of 64, and decreased this. With layers of 16, it got much worse. Takes fiddling/designing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `bond_df`, grab just useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function removes unneeded columns. It also splits the numerical / nonnummerical values.\n",
    "\n",
    "This is done for the normalizing step done later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    # get sample of bond_df\n",
    "    dataset = bond_df.sample(frac=0.1,random_state=0)\n",
    "    \n",
    "    # split data into categorical and feature\n",
    "    ds_categ = pd.get_dummies(dataset[['type']], prefix='', prefix_sep='')\n",
    "    ds_categ_col = ds_categ.columns\n",
    "    ds_label_col = 'scalar_coupling_constant'\n",
    "    \n",
    "    # remove other columns to get numerical\n",
    "    ds_numer = dataset.reset_index(drop=True)\n",
    "    dataset_dropcols = ['molecule_name','atom_index_0','type','atom_0','atom_1','atom_index_1','angle']\n",
    "    ds_numer = ds_numer.drop(columns=dataset_dropcols)\n",
    "    ds_numer_col = ds_numer.columns\n",
    "    ds = ds_numer.merge(ds_categ, right_index=True,left_index=True)\n",
    "    \n",
    "    return (ds, ds_numer_col, ds_categ_col,ds_label_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds, ds_num, ds_cat, ds_label) = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics\n",
    "* The general stats of every numerical columns is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_stats = ds[ds_num].describe().transpose()\n",
    "ds_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is split into Train/ Test sets. Numerical values are normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_norm( dataset, numer_cols, frac=0.8 ):\n",
    "    train = dataset.sample(frac=frac,random_state=0) # take frac of dataset for training\n",
    "    test = dataset.drop(train.index) # remove the training set from original set, to get test sample\n",
    "    \n",
    "    # norm values\n",
    "    train[numer_cols] = train[numer_cols].apply(norm,axis=1)\n",
    "    test[numer_cols] = test[numer_cols].apply(norm,axis=1)\n",
    "    return (train, test)\n",
    "\n",
    "def norm(x):\n",
    "    return (x - ds_stats['mean']) / ds_stats['std']\n",
    "\n",
    "def unnorm_value(x, label):\n",
    "    return (x * ds_stats['std'][label]) + ds_stats['mean'][label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds) = train_test_norm(ds, numer_cols=ds_num)\n",
    "train_labels_data = train_ds.pop(ds_label)\n",
    "test_labels_data = test_ds.pop(ds_label)\n",
    "train_labels = train_labels_data.pop(ds_label).values.reshape(-1,1)\n",
    "test_labels = test_labels_data.pop(ds_label).values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function creates the FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(32, activation='sigmoid', input_shape=[len(train_ds.keys())]),\n",
    "    layers.Dense(32, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.01)\n",
    "    optimizer = tf.keras.optimizers.Adamax(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Adamax')\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Neurel Net\n",
    "* EPOCHS is how matter training iterations to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "history = model.fit(\n",
    "  np.array(train_ds), np.array(train_labels),\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0, use_multiprocessing=False)\n",
    "# callbacks=[tfdocs.modeling.EpochDots()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference between Test and Predicted values\n",
    "* This is still normalized difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_result = model.predict(np.array(test_ds))\n",
    "diff_result = example_result - test_labels\n",
    "diff_result.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Predicted Values Plot\n",
    "* Blue is test data\n",
    "* Green is predicted by the neurel net.\n",
    "This is pretty good results! The net follows the basic pattern we can see with our eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(train_ds['x_0'],train_labels)\n",
    "plt.scatter( unnorm_value(test_ds['displacement'], 'displacement'),test_labels)\n",
    "plt.scatter( unnorm_value(test_ds['displacement'], 'displacement'),example_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to score the net for each bond type\n",
    "* All bond types are trained at once, so the model is built, trained, predicted already. Just scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_network():\n",
    "    nn_score = 0\n",
    "    for typ in bond_types:\n",
    "        # get test data of just this bond type\n",
    "        type_test_ds = test_ds[test_ds[typ] == 1]\n",
    "\n",
    "        # predict for this type\n",
    "        type_predict = model.predict(np.array(type_test_ds))\n",
    "\n",
    "        #unnorm predict and test\n",
    "        unnorm_predict = unnorm_value(type_predict, 'scalar_coupling_constant').reshape(1,-1)[0]\n",
    "        unnorm_test = unnorm_value(test_labels_data[type_test_ds.index].values, 'scalar_coupling_constant')\n",
    "\n",
    "        # Score\n",
    "        nn_score = score_type( unnorm_test, unnorm_predict ) \n",
    "\n",
    "        print( \"Type \",typ, \" has score \",nn_score )\n",
    "\n",
    "    #     plt.scatter(typ['displacement'],test_labels_data[typ.index].values)\n",
    "    #     plt.scatter(typ['displacement'],type_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Score\n",
    "* The values are around 0.7~0.8 for low EPOCHS.\n",
    "* Can achieve ~0.6 values for most bond types. This is an improvement over the previous models built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to craete a 2D potential map. This image will act as a form of image of the potential around the molecule.\n",
    "\n",
    "I anticipate trying with low resolution initially, and training a NN on the image to try and estimate the scalar coupling value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(struct_df[['x','y','z']].max())\n",
    "print(struct_df[['x','y','z']].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct_df = struct_df.set_index(['molecule_name','atom_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pot( coord, atom ):\n",
    "    disp = calc_pot_disp( coord, atom  )\n",
    "    return potential( disp, typ )\n",
    "    \n",
    "# calculcates displacement on a passed row\n",
    "def calc_pot_disp( c, a ):\n",
    "    return np.linalg.norm(np.array([a.x-c[0],a.y-c[1],a.z-c[2]]))\n",
    "    \n",
    "def get_mol_atoms( mol_name ):\n",
    "    return struct_df.loc[ struct_df.molecule_name == mol_name ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential(r, atm):\n",
    "    a = 1\n",
    "    b = 1\n",
    "    mult = 1\n",
    "    if atm != 'H':\n",
    "        mult = 10\n",
    "    return mult * 4 *((a/r)**12 - (b/r)**6)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLD CODE\n",
    "# I am trying to convert to 3d / improve it below\n",
    "\n",
    "# # struct_df.iloc[:1].apply(test_func, axis=0)\n",
    "\n",
    "# all_mols = struct_df[:10].molecule_name.unique()\n",
    "\n",
    "# # loop through all mols, for each, create potential map for all rows of that mol\n",
    "\n",
    "\n",
    "# res = 22\n",
    "# all_maps = {}\n",
    "\n",
    "# for mol in all_mols:\n",
    "    \n",
    "    \n",
    "#     # define space params / resolution / ticks\n",
    "#     x_min = y_min = -11\n",
    "#     x_max = y_max = 11\n",
    "#     x_size = x_max - x_min\n",
    "#     y_size = y_max - y_min\n",
    "#     x_ticks = x_size/res\n",
    "#     y_ticks = y_size/res\n",
    "    \n",
    "#     # empty matrix\n",
    "#     pot_map = np.zeros( (x_size, y_size) )\n",
    "    \n",
    "#     # get all atoms in mol\n",
    "#     atoms = get_mol_atoms( mol )\n",
    "    \n",
    "#     # loop through space\n",
    "#     for x in np.arange(x_min, x_max, x_ticks):\n",
    "        \n",
    "#         for y in np.arange(y_min, y_max, y_ticks):\n",
    "            \n",
    "            \n",
    "#             # calculate potential at x,y from all atoms\n",
    "#             for i,atom in atoms.iterrows():\n",
    "#                 pot_map[ int(x+11) ][ int(y+11) ] = calc_pot( (x,y), atom )\n",
    "                \n",
    "    \n",
    "#     # save map\n",
    "#     all_maps[mol] = pot_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(ds):\n",
    "    return (ds - ds.mean()) / ds.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struct_df.iloc[:1].apply(test_func, axis=0)\n",
    "\n",
    "all_mols = struct_df[:1000].molecule_name.unique()\n",
    "\n",
    "# loop through all mols, for each, create potential map for all rows of that mol\n",
    "\n",
    "\n",
    "res = 10\n",
    "all_maps = {}\n",
    "\n",
    "for mol in all_mols:\n",
    "        \n",
    "    # empty matrix\n",
    "    pot_map = np.zeros( (res, res) )\n",
    "    \n",
    "    # get all atoms in mol\n",
    "    atoms = get_mol_atoms( mol )\n",
    "    \n",
    "\n",
    "    # define space params\n",
    "    x_min = atoms.x.min()\n",
    "    x_max = atoms.x.max()\n",
    "    y_min = atoms.y.min()\n",
    "    y_max = atoms.y.max()\n",
    "    z_min = atoms.z.min()\n",
    "    z_max = atoms.z.max()\n",
    "    \n",
    "    x_width = (x_max - x_min) * 6\n",
    "    y_width = (y_max - y_min) * 6\n",
    "    z_width = (z_max - z_min) * 6 \n",
    "    \n",
    "    abs_z = 1/2*z_width - z_width/2\n",
    "    \n",
    "#     for z in np.arange(3):\n",
    "#         abs_z = z/3*z_width - z_width/2\n",
    "    \n",
    "    # loop through space\n",
    "    for x in np.arange(res):\n",
    "        abs_x = x/res*x_width - x_width/2\n",
    "\n",
    "        for y in np.arange(res):\n",
    "            abs_y = y/res*y_width - y_width/2\n",
    "\n",
    "            # calculate potential at x,y from all atoms\n",
    "            for i,atom in atoms.iterrows():\n",
    "                pot = calc_pot( (abs_x,abs_y,abs_z), atom )\n",
    "                pot_map[ x ][ y ] = pot\n",
    "    \n",
    "    # save map\n",
    "    all_maps[mol] = pot_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am checking to see if it seems reasonable the 2D potential slice / mapping has distinct features according to copupling constants. Who knows if a NN can pick on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_df[ bond_df.type == '1JHC'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.rcParams[\"figure.figsize\"] = [8,4.5]\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.imshow( all_maps['dsgdb9nsd_000001'], cmap='plasma')\n",
    "plt.show()\n",
    "plt.imshow( all_maps['dsgdb9nsd_000005'], cmap='plasma')\n",
    "plt.show()\n",
    "plt.imshow( all_maps['dsgdb9nsd_000006'], cmap='plasma')\n",
    "plt.show()\n",
    "plt.imshow( all_maps['dsgdb9nsd_000007'], cmap='plasma')\n",
    "plt.show()\n",
    "plt.imshow( all_maps['dsgdb9nsd_000009'], cmap='plasma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(all_maps['dsgdb9nsd_000077']).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb = plt.colorbar()\n",
    "# cb.set_label('Strength of Potential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mpl_toolkits import mplot3d\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "\n",
    "# data = normalize(all_maps['dsgdb9nsd_000001'])\n",
    "# xs = data.transpose((0,1,2)).ravel()\n",
    "# ys = data.transpose((1,2,0)).ravel()\n",
    "# zs = data.transpose((2,0,1)).ravel()\n",
    "\n",
    "# ax.scatter(xs,ys,zs, cmap='hot',\n",
    "#                        linewidth=0, antialiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPot = train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasetPot():\n",
    "    # get sample of bond_df\n",
    "    dataset = bond_df.sample(frac=0.1,random_state=0)\n",
    "    \n",
    "    # split data into categorical and feature\n",
    "    ds_categ = pd.get_dummies(dataset[['type']], prefix='', prefix_sep='')\n",
    "    ds_categ_col = ds_categ.columns\n",
    "    ds_label_col = 'scalar_coupling_constant'\n",
    "    \n",
    "    # remove other columns to get numerical\n",
    "    ds_numer = dataset.reset_index(drop=True)\n",
    "    dataset_dropcols = ['atom_index_0','type','atom_0','atom_1','atom_index_1','angle']\n",
    "    ds_numer = ds_numer.drop(columns=dataset_dropcols)\n",
    "    ds_numer_col = ds_numer.columns\n",
    "    ds = ds_numer.merge(ds_categ, right_index=True,left_index=True)\n",
    "    \n",
    "    # Normalize, test train split\n",
    "    (train_ds, test_ds) = train_test_norm(ds, numer_cols=ds_num)\n",
    "    train_labels_data = train_ds.pop(ds_label)\n",
    "    test_labels_data = test_ds.pop(ds_label)\n",
    "    train_labels = train_ds.pop(ds_label).values.reshape(-1,1)\n",
    "    test_labels = test_ds.pop(ds_label).values.reshape(-1,1)\n",
    "    \n",
    "    return (train_ds, test_ds, train_labels, test_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_ds = get_datasetPot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_train = pot_ds[0]\n",
    "\n",
    "# get rows where we have mol\n",
    "pot_trainMol = pot_train[ pot_train.molecule_name.isin(all_mols) ]\n",
    "\n",
    "# reset index to start at 0\n",
    "pot_trainMol = pot_trainMol.reset_index().drop(columns=['index'])\n",
    "\n",
    "# train_pot_labels = pot_trainMol['']\n",
    "\n",
    "pot_train_data = []\n",
    "pot_train_labels = []\n",
    "for i, row in pot_trainMol.iterrows():\n",
    "    potmap = list( all_maps[ row.molecule_name ].flatten())\n",
    "    label = row.pop('scalar_coupling_constant')\n",
    "    row = row.drop('molecule_name')\n",
    "    data = list(row) + potmap\n",
    "    pot_train_data.append( np.array(data) )\n",
    "    pot_train_labels.append( label )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pot = np.array( pot_train_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(128, activation='sigmoid', input_shape=[train_pot.shape[1] ]),\n",
    "    layers.Dense(128, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.01)\n",
    "    optimizer = tf.keras.optimizers.Adamax(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Adamax')\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPot = build_model()\n",
    "modelPot.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "historyPot = modelPot.fit(\n",
    "  train_pot, np.array( pot_ds[2] ),\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=0, use_multiprocessing=False)\n",
    "# callbacks=[tfdocs.modeling.EpochDots()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histPot = pd.DataFrame(historyPot.history)\n",
    "histPot['epoch'] = historyPot.epoch\n",
    "print( histPot )\n",
    "\n",
    "# plt.scatter(train_ds['x_0'],train_labels)\n",
    "plt.scatter( unnorm_value(test_ds['displacement'], 'displacement'),test_labels)\n",
    "plt.scatter( unnorm_value(test_ds['displacement'], 'displacement'),example_result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
